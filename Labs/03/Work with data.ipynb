{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Usare i dati\n",
        "\n",
        "I dati sono la base in cui vengono compilati i modelli di Machine Learning. La gestione centralizzata dei dati nel cloud e la sua accessibilità ai team di data scientist che eseguono esperimenti e modelli di training su più workstation e destinazioni di calcolo è una parte importante di qualsiasi soluzione di data science professionale.\n",
        "\n",
        "In questo notebook verranno esaminati due oggetti di Azure Machine Learning per l'uso dei dati: *archivi dati* e *asset di dati*.\n",
        "\n",
        "## Prima di iniziare\n",
        "\n",
        "Per eseguire il codice in questo notebook, è necessaria la versione più recente del pacchetto **azureml-ai-ml** . Eseguire la cella seguente per verificare che sia installata.\n",
        "\n",
        "> **Nota**:\n",
        "> Se il pacchetto **azure-ai-ml** non è installato, eseguire `pip install azure-ai-ml` per installarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Connettersi all'area di lavoro\n",
        "\n",
        "Dopo aver installato i pacchetti SDK necessari, è ora possibile connettersi all'area di lavoro.\n",
        "\n",
        "Per connettersi a un'area di lavoro, sono necessari parametri di identificatore: ID sottoscrizione, nome del gruppo di risorse e nome dell'area di lavoro. Il nome del gruppo di risorse e il nome dell'area di lavoro sono già compilati automaticamente. Per completare il comando è necessario solo l'ID sottoscrizione.\n",
        "\n",
        "Per trovare i parametri necessari, fare clic sulla sottoscrizione e sul nome dell'area di lavoro in alto a destra di Studio. Verrà aperto un riquadro a destra.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Copiare l'ID sottoscrizione e sostituire **YOUR-SUBSCRIPTION-ID** con il valore copiato. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Elencare gli archivi dati\n",
        "\n",
        "Quando si crea l'area di lavoro di Azure Machine Learning, viene creato anche un account di archiviazione di Azure. L'account di archiviazione include l'archiviazione BLOB e file e viene automaticamente connesso all'area di lavoro come **archivi dati**. È possibile elencare tutti gli archivi dati connessi all'area di lavoro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Si noti che `workspaceblobstore` si connette **all'archivio azureml-blob-...** contenitore esplorato in precedenza. si `workspacefilestore` connette al **codice-...** condivisione file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Creare un archivio dati\n",
        "\n",
        "Ogni volta che si vuole connettere un altro servizio di archiviazione di Azure all'area di lavoro di Azure Machine Learning, è possibile creare un archivio dati. Si noti che la creazione di un archivio dati crea la connessione tra l'area di lavoro e l'archiviazione e non crea il servizio di archiviazione stesso. \n",
        "\n",
        "Per creare un archivio dati e connettersi a una risorsa di archiviazione (già esistente), è necessario specificare:\n",
        "\n",
        "- Classe da indicare con il tipo di servizio di archiviazione che si vuole connettere. L'esempio seguente si connette a un archivio BLOB (`AzureBlobDatastore`).\n",
        "- `name`: nome visualizzato dell'archivio dati nell'area di lavoro di Azure Machine Learning.\n",
        "- `description`: Descrizione facoltativa per fornire altre informazioni sull'archivio dati.\n",
        "- `account_name`: nome dell'account di archiviazione di Azure.\n",
        "- `container_name`: nome del contenitore in cui archiviare i BLOB nell'account di archiviazione di Azure.\n",
        "- `credentials`: specificare il metodo di autenticazione e le credenziali per l'autenticazione. L'esempio seguente usa una chiave dell'account.\n",
        "\n",
        "**Importante**: \n",
        "- Sostituire **YOUR-STORAGE-ACCOUNT-NAME** con il nome dell'account di archiviazione creato automaticamente. \n",
        "- Sostituire **XXXX-XXXX** per `account_key` con la chiave dell'account di archiviazione di Azure. \n",
        "\n",
        "Tenere presente che è possibile recuperare la chiave dell'account passando alla [portale di Azure](https://portal.azure.com), passare all'account di archiviazione, dalla scheda **Chiavi di accesso**, copiare il valore **chiave** per key1 o key2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Elencare di nuovo gli archivi dati per verificare che sia stato creato un nuovo archivio dati denominato `blob_training_data` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Creare asset di dati\n",
        "\n",
        "Per puntare a una cartella o a un file specifico in un archivio dati, è possibile creare asset di dati. Esistono tre tipi di asset di dati:\n",
        "\n",
        "- `URI_FILE` punta a un file specifico.\n",
        "- `URI_FOLDER` punta a una cartella specifica.\n",
        "- `MLTABLE` punta a un file MLTable che specifica come leggere uno o più file all'interno di una cartella.\n",
        "\n",
        "Verranno creati tutti e tre i tipi di asset di dati per verificarne le differenze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Per creare un `URI_FILE` asset di dati, è necessario specificare un percorso che punta a un file specifico. Il percorso può essere un percorso locale o un percorso cloud.\n",
        "\n",
        "Nell'esempio seguente si creerà un asset di dati facendo riferimento a un percorso *locale* . Per assicurarsi che i dati siano sempre disponibili quando si usa l'area di lavoro di Azure Machine Learning, i file locali verranno caricati automaticamente nell'archivio dati predefinito. In questo caso, il `diabetes.csv` file verrà caricato nella cartella **LocalUpload** nell'archivio dati **workspaceblobstore** . \n",
        "\n",
        "Per creare un asset di dati da un file locale, eseguire la cella seguente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Per creare un `URI_FOLDER` asset di dati, è necessario specificare un percorso che punta a una cartella specifica. Il percorso può essere un percorso locale o un percorso cloud.\n",
        "\n",
        "Nell'esempio seguente si creerà un asset di dati facendo riferimento a un percorso *cloud* . Il percorso non deve ancora esistere. La cartella verrà creata quando i dati vengono caricati nel percorso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Per creare un `MLTable` asset di dati, è necessario specificare un percorso che punta a una cartella che contiene un file MLTable. Il percorso può essere un percorso locale o un percorso cloud. \n",
        "\n",
        "Nell'esempio seguente si creerà un asset di dati facendo riferimento a un percorso *locale* che contiene un file MLTable e CSV. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Per verificare che i nuovi asset di dati siano stati creati, è possibile elencare di nuovo tutti gli asset di dati nell'area di lavoro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Leggere i dati nel notebook\n",
        "\n",
        "Inizialmente, è possibile usare gli asset di dati nei notebook per esplorare i dati e sperimentare i modelli di Machine Learning. Tutti `URI_FILE` gli asset di dati o `URI_FOLDER` di tipo vengono letti come si leggerebbero normalmente i dati. Ad esempio, per leggere un file CSV a cui punta un asset di dati, è possibile usare la funzione `read_csv()`pandas . \n",
        "\n",
        "Un `MLTable` asset di dati di tipo è già *letto* dal file **MLTable** , che specifica lo schema e come interpretare i dati. Poiché i dati sono già *letti*, è possibile convertire facilmente un asset di dati MLTable in un dataframe pandas. \n",
        "\n",
        "È necessario installare la `mltable` libreria (eseguita nel terminale). È quindi possibile convertire l'asset di dati in un dataframe e visualizzare i dati.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Usare i dati in un processo\n",
        "\n",
        "Dopo aver usato un notebook per la sperimentazione. È possibile usare gli script per eseguire il training di modelli di Machine Learning. Uno script può essere eseguito come processo e per ogni processo è possibile specificare input e output. \n",
        "\n",
        "È possibile usare **asset di dati** o **percorsi dell'archivio dati** come input o output di un processo. \n",
        "\n",
        "Le celle seguenti creano lo script **move-data.py** nella cartella **src** . Lo script legge i dati di input con la `read_csv()` funzione . Lo script archivia quindi i dati come file CSV nel percorso di output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Per inviare un processo che esegue lo script **move-data.py** , eseguire la cella seguente. \n",
        "\n",
        "Il processo è configurato per l'uso dell'asset `diabetes-local`di dati , che punta al file ** didiabetes.csv** locale come input. L'output è un percorso che punta a una cartella nel nuovo archivio `blob_training_data`dati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}