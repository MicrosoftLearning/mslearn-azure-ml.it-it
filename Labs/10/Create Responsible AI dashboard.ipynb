{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creare un dashboard di intelligenza artificiale responsabile per valutare i modelli\n",
        "\n",
        "Quando si confrontano e si valutano i modelli di Machine Learning, è consigliabile esaminare più semplicemente la metrica delle prestazioni. Azure Machine Learning consente di creare un dashboard di intelligenza artificiale responsabile per esplorare le prestazioni del modello in coorti diverse dei dati. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparare i dati\n",
        "\n",
        "Per creare il dashboard di intelligenza artificiale responsabile, è necessario un set di dati di training e test, archiviato come file Parquet e registrato come asset di dati.\n",
        "\n",
        "I dati vengono attualmente archiviati come file CSV. Convertirli in file Parquet. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025462688
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Prima di continuare\n",
        "\n",
        "Per eseguire il codice in questo notebook, è necessaria la versione più recente del pacchetto **azureml-ai-ml** . Eseguire la cella seguente per verificare che sia installata.\n",
        "\n",
        "> **Nota**:\n",
        "> Se il pacchetto **azure-ai-ml** non è installato, eseguire `pip install azure-ai-ml` per installarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025466902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Connettersi all'area di lavoro\n",
        "\n",
        "Dopo aver installato i pacchetti SDK necessari, è ora possibile connettersi all'area di lavoro.\n",
        "\n",
        "Per connettersi a un'area di lavoro, sono necessari parametri di identificatore: ID sottoscrizione, nome del gruppo di risorse e nome dell'area di lavoro. Il nome del gruppo di risorse e il nome dell'area di lavoro sono già compilati automaticamente. Per completare il comando è necessario solo l'ID sottoscrizione.\n",
        "\n",
        "Per trovare i parametri necessari, fare clic sulla sottoscrizione e sul nome dell'area di lavoro in alto a destra di Studio. Verrà aperto un riquadro a destra.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Copiare l'ID sottoscrizione e sostituire **YOUR-SUBSCRIPTION-ID** con il valore copiato. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creare gli asset di dati\n",
        "\n",
        "Per creare il dashboard di intelligenza artificiale responsabile, è necessario registrare i set di dati di training e test come asset di dati **MLtable** . Gli asset di dati MLtable fanno riferimento ai file Parquet creati in precedenza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025474944
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Creare la pipeline per creare il dashboard di intelligenza artificiale responsabile\n",
        "\n",
        "Per creare il dashboard, si creerà una pipeline con componenti predefiniti registrati per impostazione predefinita nell'area di lavoro di Azure Machine Learning."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registrare il modello\n",
        "\n",
        "È già stato eseguito il training di un modello di Machine Learning. Il modello stima se un paziente ha il diabete. Tutti i file del modello vengono archiviati nella `model` cartella . \n",
        "\n",
        "Registrare il modello puntando alla `model` cartella e al relativo contenuto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025488380
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Creare la pipeline\n",
        "\n",
        "Per creare il dashboard di intelligenza artificiale responsabile, si creerà una pipeline usando i componenti predefiniti. È possibile scegliere quali componenti usare e quali funzionalità includere nel dashboard. Verrà creato un dashboard che include l'analisi degli errori e l'interpretazione del modello. \n",
        "\n",
        "Accanto alle funzionalità di intelligenza artificiale responsabili, una pipeline per creare un dashboard deve includere un componente all'inizio per costruire il dashboard e un componente alla fine per raccogliere tutte le informazioni dettagliate generate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025518893
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Dopo aver recuperato tutti i componenti da usare, è possibile compilare la pipeline e connettere i componenti nell'ordine appropriato:\n",
        "\n",
        "1. Costruire il dashboard.\n",
        "1. Aggiungere l'analisi degli errori.\n",
        "1. Aggiungere spiegazioni.\n",
        "1. Raccogliere tutte le informazioni dettagliate e visualizzarle nel dashboard."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ora la pipeline è stata compilata, è necessario definire i due input necessari: il set di dati di training e di test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025520971
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Infine, verranno inseriti tutti gli elementi: assegnare gli input alla pipeline e impostare la colonna di destinazione (etichetta stimata)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025542446
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Eseguire la pipeline\n",
        "\n",
        "Dopo aver compilato correttamente la pipeline, è possibile inviarla. Il codice seguente invia la pipeline e controlla lo stato della pipeline. È anche possibile visualizzare lo stato della pipeline in Studio. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al termine della pipeline, è possibile esaminare il dashboard in Studio. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025587559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Get handle to azureml registry for the RAI built in components\n",
        "registry_name = \"azureml\"\n",
        "ml_client_registry = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    registry_name=registry_name,\n",
        ")\n",
        "print(ml_client_registry)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Register the model\n",
        "\n",
        "A machine learning model has already been trained for you. The model predicts whether a patient has diabetes. All model files are stored in the `model` folder. \n",
        "\n",
        "Register the model by pointing to the `model` folder and its contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025596451
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "file_model = Model(\n",
        "    path=\"model\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    name=\"local-mlflow-diabetes\",\n",
        "    description=\"Model created from local file.\",\n",
        ")\n",
        "model = ml_client.models.create_or_update(file_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the pipeline\n",
        "\n",
        "To create the responsible AI dashboard, you'll create a pipeline using the prebuilt components. You can choose which components to use, and which features you want to include in your dashboard. You'll create a dashboard that includes error analysis and model interpretability. \n",
        "\n",
        "Next to the responsible AI features, a pipeline to build a dashboard needs to include a component at the start to construct the dashboard, and a component at the end to gather all generated insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025619196
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model_name = model.name\n",
        "expected_model_id = f\"{model_name}:1\"\n",
        "azureml_model_id = f\"azureml:{expected_model_id}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025626888
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "label = \"latest\"\n",
        "\n",
        "rai_constructor_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\n",
        ")\n",
        "\n",
        "# we get latest version and use the same version for all components\n",
        "version = rai_constructor_component.version\n",
        "print(\"The current version of RAI built-in components is: \" + version)\n",
        "\n",
        "rai_erroranalysis_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\n",
        ")\n",
        "\n",
        "rai_explanation_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\n",
        ")\n",
        "\n",
        "rai_gather_component = ml_client_registry.components.get(\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you've retrieved all components you want to use, you can build the pipeline and connect the components in the appropriate order:\n",
        "\n",
        "1. Construct the dashboard.\n",
        "1. Add error analysis.\n",
        "1. Add explanations.\n",
        "1. Gather all insights and visualize them in the dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677026156980
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, dsl\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "compute_name = \"aml-cluster\"\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=compute_name,\n",
        "    description=\"RAI insights on diabetes data\",\n",
        "    experiment_name=f\"RAI_insights_{model_name}\",\n",
        ")\n",
        "def rai_decision_pipeline(\n",
        "    target_column_name, train_data, test_data\n",
        "):\n",
        "    # Initiate the RAIInsights\n",
        "    create_rai_job = rai_constructor_component(\n",
        "        title=\"RAI dashboard diabetes\",\n",
        "        task_type=\"classification\",\n",
        "        model_info=expected_model_id,\n",
        "        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
        "        train_dataset=train_data,\n",
        "        test_dataset=test_data,\n",
        "        target_column_name=target_column_name,\n",
        "    )\n",
        "    create_rai_job.set_limits(timeout=30)\n",
        "\n",
        "    # Add error analysis\n",
        "    error_job = rai_erroranalysis_component(\n",
        "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "    )\n",
        "    error_job.set_limits(timeout=10)\n",
        "\n",
        "    # Add explanations\n",
        "    explanation_job = rai_explanation_component(\n",
        "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        comment=\"add explanation\", \n",
        "    )\n",
        "    explanation_job.set_limits(timeout=10)\n",
        "\n",
        "    # Combine everything\n",
        "    rai_gather_job = rai_gather_component(\n",
        "        constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
        "        insight_3=error_job.outputs.error_analysis,\n",
        "        insight_4=explanation_job.outputs.explanation,\n",
        "    )\n",
        "    rai_gather_job.set_limits(timeout=10)\n",
        "\n",
        "    rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
        "\n",
        "    return {\n",
        "        \"dashboard\": rai_gather_job.outputs.dashboard,\n",
        "    }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the pipeline has been built, you need to define the two necessary inputs: the training and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677025638275
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "target_feature = \"Diabetic\"\n",
        "\n",
        "diabetes_train_pq = Input(\n",
        "    type=\"mltable\",\n",
        "    path=f\"azureml:{input_train_data}:{data_version}\",\n",
        "    mode=\"download\",\n",
        ")\n",
        "diabetes_test_pq = Input(\n",
        "    type=\"mltable\",\n",
        "    path=f\"azureml:{input_test_data}:{data_version}\",\n",
        "    mode=\"download\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we'll put everything together: assign the inputs to the pipeline and set the target column (the predicted label)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677026333108
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "from azure.ai.ml import Output\n",
        "\n",
        "# Pipeline to construct the RAI Insights\n",
        "insights_pipeline_job = rai_decision_pipeline(\n",
        "    target_column_name=\"Diabetic\",\n",
        "    train_data=diabetes_train_pq,\n",
        "    test_data=diabetes_test_pq,\n",
        ")\n",
        "\n",
        "# Workaround to enable the download\n",
        "rand_path = str(uuid.uuid4())\n",
        "insights_pipeline_job.outputs.dashboard = Output(\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
        "    mode=\"upload\",\n",
        "    type=\"uri_folder\",\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the pipeline\n",
        "\n",
        "When you've successfully built the pipeline, you can submit it. The following code will submit the pipeline and check the status of the pipeline. You can also view the pipeline's status in the studio. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677026340892
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import PipelineJob\n",
        "from IPython.core.display import HTML\n",
        "from IPython.display import display\n",
        "import time\n",
        "\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
        "    assert created_job is not None\n",
        "\n",
        "    print(\"Pipeline job can be accessed in the following URL:\")\n",
        "    display(HTML('<a href=\"{0}\">{0}</a>'.format(created_job.studio_url)))\n",
        "\n",
        "    while created_job.status not in [\n",
        "        \"Completed\",\n",
        "        \"Failed\",\n",
        "        \"Canceled\",\n",
        "        \"NotResponding\",\n",
        "    ]:\n",
        "        time.sleep(30)\n",
        "        created_job = ml_client.jobs.get(created_job.name)\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\n",
        "    assert created_job.status == \"Completed\"\n",
        "    return created_job\n",
        "\n",
        "\n",
        "# This is the actual submission\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the pipeline is completed, you can review the dashboard in the studio. "
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}