{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distribuire in un endpoint batch\n",
        "\n",
        "Si supponga che una clinica sanitaria prenda le misurazioni dei pazienti tutto il giorno, salvando i dettagli per ogni paziente in un file separato. Quindi durante la notte, il modello di stima del diabete può essere usato per elaborare tutti i dati dei pazienti del giorno come batch, generando stime che saranno in attesa il mattino seguente in modo che la clinica possa seguire con i pazienti che sono previsti essere a rischio di diabete. Con Azure Machine Learning è possibile eseguire questa operazione creando un endpoint batch; ed è ciò che si implementerà in questo esercizio.\n",
        "\n",
        "## Prima di iniziare\n",
        "\n",
        "È necessaria la versione più recente del pacchetto  **azureml-ai-ml** per eseguire il codice in questo notebook. Eseguire la cella seguente per verificare che sia installata.\n",
        "\n",
        "> **Nota**:\n",
        "> Se il pacchetto **azure-ai-ml** non è installato, eseguirlo `pip install azure-ai-ml` per installarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816557578
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Connettersi all'area di lavoro\n",
        "\n",
        "Con i pacchetti SDK necessari installati, è ora possibile connettersi all'area di lavoro.\n",
        "\n",
        "Per connettersi a un'area di lavoro, sono necessari parametri di identificatore: ID sottoscrizione, nome del gruppo di risorse e nome dell'area di lavoro. Il nome del gruppo di risorse e il nome dell'area di lavoro sono già compilati. È necessario solo l'ID sottoscrizione per completare il comando.\n",
        "\n",
        "Per trovare i parametri necessari, fare clic sulla sottoscrizione e sul nome dell'area di lavoro nella parte superiore destra di Studio. Un riquadro verrà aperto a destra.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Copiare l'ID sottoscrizione e sostituire **YOUR-SUBSCRIPTION-ID** con il valore copiato. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Registrare il modello\n",
        "\n",
        "Le distribuzioni batch possono distribuire solo i modelli registrati nell'area di lavoro. Verrà registrato un modello MLflow archiviato nella cartella locale `model` . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816564779
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Creare un endpoint batch\n",
        "\n",
        "Un endpoint batch è un endpoint HTTPS che le applicazioni possono chiamare per attivare un processo di assegnazione dei punteggi batch. Un nome dell'endpoint batch deve essere univoco all'interno di un'area di Azure. Si userà la `datetime` funzione per generare un nome univoco in base alla data e all'ora correnti. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816570921
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Per creare un endpoint con la `BatchEndpoint` classe, è necessario specificare il nome e facoltativamente una descrizione. Dopo aver creato un endpoint, si distribuirà un modello nell'endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANTE Attendere fino a quando l'endpoint non viene creato prima di continuare. Verrà visualizzata una notifica verde nello studio. </p>\n",
        "\n",
        "## Creare la distribuzione\n",
        "\n",
        "Una distribuzione è un set di risorse necessarie per ospitare il modello che esegue l'inferenza effettiva. Verrà creata una distribuzione per l'endpoint usando la `BatchDeployment` classe . \n",
        "\n",
        "Poiché si distribuisce un modello MLflow, non è necessario uno script di assegnazione dei punteggi o definire l'ambiente. Azure Machine Learning creerà automaticamente tali asset. Il `MLmodel` file nella `model` cartella viene usato per comprendere gli input e gli output previsti sono del modello.\n",
        "\n",
        "Si distribuirà un modello con i parametri seguenti:\n",
        "\n",
        "- `name`: nome della distribuzione.\n",
        "- `description`: Descrizione facoltativa per chiarire ulteriormente cosa rappresenta la distribuzione.\n",
        "- `endpoint_name`: nome dell'endpoint creato in precedenza, è necessario distribuire il modello.\n",
        "- `model`: nome del modello registrato.\n",
        "- `compute`: calcolo da usare quando si richiama il modello distribuito per generare stime.\n",
        "- `instance_count`: conteggio dei nodi di calcolo da usare per la generazione di stime.\n",
        "- `max_concurrency_per_instance`: numero massimo di script di assegnazione dei punteggi paralleli eseguiti per ogni nodo di calcolo.\n",
        "- `mini_batch_size`: numero di file passati per esecuzione dello script di assegnazione dei punteggi.\n",
        "- `output_action`: ogni nuova stima verrà aggiunta come nuova riga al file di output.\n",
        "- `output_file_name`: file a cui verranno aggiunte le stime.\n",
        "- `retry_settings`: le impostazioni per un mini-batch hanno esito negativo.\n",
        "- `logging_level`: livello di verbosità del log. I valori consentiti sono `warning`, `info`e `debug`. \n",
        "\n",
        "L'esecuzione della cella seguente configura e crea la distribuzione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816601458
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANTE Attendere il completamento della distribuzione prima di continuare. Verrà visualizzata una notifica verde nello studio. </p>\n",
        "\n",
        "È possibile distribuire più modelli in un endpoint. È possibile impostare la distribuzione predefinita per specificare quale modello deve essere usato per impostazione predefinita quando si chiama un endpoint batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANTE Attendere fino a quando la distribuzione predefinita non è impostata prima di continuare. Verrà visualizzata una notifica verde nello studio. </p>\n",
        "\n",
        "## Preparare i dati per le stime batch\n",
        "\n",
        "`data` Nella cartella sono disponibili file CSV con dati non etichettati. Si creerà un asset di dati che punta ai file nella `data` cartella, che verrà usato come input per il processo batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817132589
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Inviare il processo\n",
        "\n",
        "Dopo aver distribuito un modello in un endpoint batch e avere un asset dati senza etichetta, è possibile richiamare l'endpoint per generare stime sui dati non etichettati.\n",
        "\n",
        "Prima di tutto, si definirà l'input facendo riferimento all'asset di dati registrato. Verrà quindi richiamato l'endpoint, che invierà un processo della pipeline. È possibile usare l'URL del processo per monitorarlo in Studio. Il processo conterrà un processo figlio che rappresenta l'esecuzione dello script di assegnazione dei punteggi (generato) per ottenere le stime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ottenere i risultati\n",
        "\n",
        "Al termine del processo della pipeline che richiama l'endpoint batch, è possibile visualizzare i risultati. Tutte le stime vengono raccolte nel `predictions.csv` file archiviato nell'archivio dati predefinito. È possibile scaricare il file e visualizzare i dati eseguendo le celle seguenti. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817134786
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import BatchEndpoint\n",
        "\n",
        "# create a batch endpoint\n",
        "endpoint = BatchEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"A batch endpoint for classifying diabetes in patients\",\n",
        ")\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the endpoint is created before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Create the deployment\n",
        "\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `BatchDeployment` class. \n",
        "\n",
        "Since you're deploying an MLflow model, you don't need a scoring script or define the environment. Azure Machine Learning will automatically create those assets for you. The `MLmodel` file in the `model` folder is used to understand what the expected inputs and outputs are of the model.\n",
        "\n",
        "You'll deploy a model with the following parameters:\n",
        "\n",
        "- `name`: Name of the deployment.\n",
        "- `description`: Optional description to further clarify what the deployment represents.\n",
        "- `endpoint_name`: Name of the previously created endpoint the model should be deployed to.\n",
        "- `model`: Name of the registered model.\n",
        "- `compute`: Compute to be used when invoking the deployed model to generate predictions.\n",
        "- `instance_count`: Count of compute nodes to use for generating predictions.\n",
        "- `max_concurrency_per_instance`: Maximum number of parallel scoring script runs per compute node.\n",
        "- `mini_batch_size`: Number of files passed per scoring script run.\n",
        "- `output_action`: Each new prediction will be appended as a new row to the output file.\n",
        "- `output_file_name`: File to which predictions will be appended.\n",
        "- `retry_settings`: Settings for a mini-batch fails.\n",
        "- `logging_level`: The log verbosity level. Allowed values are `warning`, `info`, and `debug`. \n",
        "\n",
        "Running the following cell will configure and create the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817147601
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\n",
        "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
        "\n",
        "deployment = BatchDeployment(\n",
        "    name=\"classifier-diabetes-mlflow\",\n",
        "    description=\"A diabetes classifier\",\n",
        "    endpoint_name=endpoint.name,\n",
        "    model=model,\n",
        "    compute=\"aml-cluster\",\n",
        "    instance_count=2,\n",
        "    max_concurrency_per_instance=2,\n",
        "    mini_batch_size=2,\n",
        "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "    output_file_name=\"predictions.csv\",\n",
        "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
        "    logging_level=\"info\",\n",
        ")\n",
        "ml_client.batch_deployments.begin_create_or_update(deployment)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the deployment is completed before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "You can deploy multiple models to an endpoint. You can set the default deployment to specify which model should be used by default when calling a batch endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816665145
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "endpoint.defaults = {}\n",
        "\n",
        "endpoint.defaults[\"deployment_name\"] = deployment.name\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the default deployment is set before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Prepare the data for batch predictions\n",
        "\n",
        "In the `data` folder you'll find CSV files with unlabeled data. You'll create a data asset that points to the files in the `data` folder, which you'll use as input for the batch job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816672949
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "data_path = \"./data\"\n",
        "dataset_name = \"patient-data-unlabeled\"\n",
        "\n",
        "patient_dataset_unlabeled = Data(\n",
        "    path=data_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"An unlabeled dataset for diabetes classification\",\n",
        "    name=dataset_name,\n",
        ")\n",
        "ml_client.data.create_or_update(patient_dataset_unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816675432
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "patient_dataset_unlabeled = ml_client.data.get(\n",
        "    name=\"patient-data-unlabeled\", label=\"latest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit the job\n",
        "\n",
        "Now that you have deployed a model to a batch endpoint, and have an unlabeled data asset, you're ready to invoke the endpoint to generate predictions on the unlabeled data.\n",
        "\n",
        "First, you'll define the input by referring to the registered data asset. Then, you'll invoke the endpoint, which will submit a pipeline job. You can use the job URL to monitor it in the Studio. The job will contain a child job that represents the running of the (generated) scoring script to get the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667816677507
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "input = Input(type=AssetTypes.URI_FOLDER, path=patient_dataset_unlabeled.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817161221
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "job = ml_client.batch_endpoints.invoke(\n",
        "    endpoint_name=endpoint.name, \n",
        "    input=input)\n",
        "\n",
        "ml_client.jobs.get(job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the results\n",
        "\n",
        "When the pipeline job that invokes the batch endpoint is completed, you can view the results. All predictions are collected in the `predictions.csv` file that is stored in the default datastore. You can download the file and visualize the data by running the following cells. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817536367
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ml_client.jobs.download(name=job.name, download_path=\".\", output_name=\"score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817544534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "with open(\"predictions.csv\", \"r\") as f:\n",
        "    data = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817550830
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "import pandas as pd\n",
        "\n",
        "score = pd.DataFrame(\n",
        "    literal_eval(data.replace(\"\\n\", \",\")), columns=[\"file\", \"prediction\"]\n",
        ")\n",
        "score"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}